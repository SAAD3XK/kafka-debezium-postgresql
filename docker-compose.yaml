version: '3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-enterprise-kafka:7.6.0
    container_name: kafka
    ports:
      - 29092:29092
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT, PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092, PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    restart: always

  debezium:
    image: debezium/connect:2.5
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      STATUS_STORAGE_TOPIC: connect_statuses
      OFFSET_STORAGE_TOPIC: connect_offsets
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      # CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # ENABLE_DEBEZIUM_SCRIPTING: 'true'
    depends_on:
      - kafka
    ports:
      - 8083:8083

  debezium-connector:
    build:
      context: ./src/debezium_connector
      dockerfile: Dockerfile
    env_file: .env
    depends_on:
      - debezium
    container_name: debezium-connector-container
    environment:
      DEBEZIUM_SERVER: "http://debezium:8083/connectors/"
      KAFKA_SERVER: "kafka:29092"
      TOPIC_NAME: "rds_first_topic"
      # comma-separated list of tables to capture data from
      TABLE_LIST: "test_table"

  # pyspark_consumer:
  #   build:
  #     context: ./src/pyspark_consumer
  #     dockerfile: Dockerfile
  #   container_name: pyspark_consumer
  #   depends_on:
  #     - kafka
  #   environment:
  #     KAFKA_BOOTSTRAP_SERVERS: "kafka:29092"
  #     INPUT_TOPIC: "rds_first_topic"
  #     OUTPUT_TOPIC: "output_topic_sink"

  jupyter:
    build:
      context: ./src/jupyter_experiment
      dockerfile: Dockerfile
    container_name: experiment_notebook
    ports:
      - 8888:8888
    volumes:
      - ./notebooks:/app/notebooks
    environment:
      KAFKA_BOOTSTRAP_SERVERS: "kafka:29092"
      INPUT_TOPIC: "rds_first_topic"
      OUTPUT_TOPIC: "output_topic_sink"
    depends_on:
    - kafka
  #   # command: bash -c "pip install pyspark==3.5.1 confluent-kafka==2.3.0 && start-notebook.sh --NotebookApp.token='' --NotebookApp.password=''"
  
  # schema-registry:
  #   image: confluentinc/cp-schema-registry:7.6.0
    # environment:
    #   - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
    #   - SCHEMA_REGISTRY_HOST_NAME=schema-registry
    #   - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8081,http://localhost:8081
  #   ports:
  #     - 8081:8081
  #   depends_on:
  #     - zookeeper
  #     - kafka